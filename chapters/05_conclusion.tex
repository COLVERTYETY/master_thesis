\section{Conclusion}

\subsection{Revisiting the Research Questions}
This research set out to explore how AI-driven augmented reality interfaces can enable intuitive, collaborative, and cognitively empowering experiences for users.
Addressing each research question individually, the findings from the Totem and LLM Whiteboard projects provide insights into the unique affordances, challenges, and benefits that AI brings to augmented reality.

\begin{itemize}
    \item \textbf{What challenges are associated with designing for low-signaling, high-possibility affordances?} Designing low-signaling, high-possibility affordances presents a significant challenge in maintaining user intuition while allowing for a wide range of potential interactions.
    Both the Totem and LLM Whiteboard projects encountered this balance, where minimal visual cues needed to guide users through expansive creative possibilities.
    The Totem platform, for instance, relied on user-friendly, gesture-based interactions for real-time art creation, while the LLM Whiteboard introduced semantic interpretation to reduce cognitive load in creative coding tasks.
    These approaches illustrate that the challenge lies in subtly guiding user intent without constraining creativity—a goal achieved by embedding AI to act as an interpretive layer, dynamically providing context-sensitive guidance.
    
    \item \textbf{How can users benefit from AR to effectively collaborate with an AI system?} The projects demonstrated that AR’s immersive and spatial capabilities allow AI to become an intuitive extension of the user's creative process.
    The Totem platform enabled users to collaborate with generative AI models to create and animate digital art with natural gestures, making the AI a seamless partner in the creative workflow.
    Similarly, the LLM Whiteboard facilitated collaborative coding by allowing users to issue high-level commands that the AI translated into executable code within an AR environment.
    These applications indicate that AR can serve as an effective interface for AI collaboration by bridging physical actions and digital responses, fostering a co-creative environment that amplifies user capabilities without demanding extensive training.
    
    \item \textbf{How do AI-driven affordances differ from traditional affordances?} Unlike traditional affordances, which provide explicit cues on potential interactions, AI-driven affordances can adapt and respond to user intent with limited visual prompts.
    This dynamic nature was evident in the Totem and LLM Whiteboard projects, where AI enabled low-signaling affordances that allowed for complex interactions with minimal guidance.
    In these systems, the AI not only interprets user input but also offers real-time adaptive responses that evolve with user actions, transforming affordances from static cues to fluid, context-aware interactions.
    This shift reveals that AI-driven affordances are fundamentally more flexible, fostering a dynamic and responsive interaction paradigm that contrasts with the fixed affordances of traditional HCI.
\end{itemize}


\subsection{Contributions to the Field}

This research contributes to HCI by demonstrating how AI-driven augmented reality interfaces can create intuitive, cognitively supportive environments that enable creative expression with minimal input.
The Totem and LLM Whiteboard projects offer concrete advancements in AI-enabled AR, expanding the possibilities of user interaction with intelligent systems.

\begin{itemize}
    \item \textbf{Advancements in Low-Signaling, High-Possibility Affordances:} By addressing the challenge of guiding users in high-possibility environments with minimal explicit cues, this research contributes novel insights into affordance design within HCI.
    The Totem platform illustrated how gesture-based interaction with AI models, such as SDXL Turbo for image generation and First Order Motion for animation, allows users to create and interact with digital art without extensive training or instruction.
    This low-signaling design leverages AI’s interpretative power to maintain user autonomy while offering vast creative potential.
    Such advancements push the boundaries of affordances by allowing users to engage in complex interactions seamlessly, broadening HCI’s approach to minimal guidance systems.

    \item  \textbf{Innovative Models of AI-User Collaboration:} The research contributes a framework for AI-augmented AR that supports real-time collaboration between users and intelligent systems.
    The Totem project enables users to work alongside AI models for visual art creation, while the LLM Whiteboard offers a collaborative coding environment where users direct the AI through high-level commands to produce code in real-time.
    These models reveal how AI-AR interfaces can extend beyond passive tools, becoming active partners that adapt to user input and intent.
    This integration of AI as a collaborative entity provides a foundation for further exploration in AI-driven HCI, particularly in fields that require interactive, co-creative processes.
    
    \item \textbf{Enhanced Cognitive and Creative Capacities through Adaptive Affordances:} The adaptive affordances in Totem and LLM Whiteboard show how AI in AR can reduce cognitive load, enabling users to focus on high-level tasks without being bogged down by technical details.
    By embedding real-time, AI-driven guidance that evolves with user input, these platforms illustrate how adaptive affordances can enhance cognitive capacity.
    This contribution addresses a gap in traditional HCI affordance models, offering a new approach where affordances are fluid and responsive, adjusting in real-time to support users’ cognitive and creative processes.

\end{itemize}

Together, these contributions demonstrate how AI-driven AR interfaces can redefine user interaction within HCI by enabling intuitive, low-signaling environments that foster creative collaboration and adapt to the user’s cognitive needs.
This research thus points toward future HCI applications that extend beyond static interfaces, exploring the potential of AI-augmented environments to become seamless extensions of human thought and creativity.

\subsection{Future Implications}

The insights gained from this research suggest that AI-driven augmented reality interfaces hold transformative potential for multiple fields and offer a glimpse into the future of HCI.
The Totem and LLM Whiteboard platforms highlight the following promising directions and emerging trends:

\textbf{Broadening Access to Creative and Educational Tools:}
By leveraging adaptive, low-signaling affordances, platforms like Totem could inspire new approaches to digital art and creative education.
As AI-driven interfaces become more accessible, there is an opportunity to democratize complex creative processes, empowering people from diverse backgrounds to engage in digital creation without extensive technical knowledge.
In education, similar interfaces could provide students with hands-on, immersive learning experiences, simplifying the learning of complex subjects through real-time interaction with AI.

\textbf{Enabling More Intuitive and Productive Remote Collaboration:}
The collaborative coding capabilities demonstrated in the LLM Whiteboard suggest potential applications in remote work, where interactive AI-AR platforms could support real-time co-creation across distances.
This could reshape team dynamics by enabling distributed teams to work with a virtual AI collaborator, aiding in ideation, code generation, and design work.
Such tools could foster a more dynamic, responsive, and engaging remote working environment, improving both productivity and job satisfaction.

\textbf{Paving the Way for Adaptive, Context-Aware Interfaces:}
The responsive nature of AI-driven affordances in AR suggests a future where interfaces become increasingly personalized and adaptable.
These systems could support users across diverse fields, from healthcare to engineering, by providing just-in-time information, guidance, or control based on context and user behavior.
This adaptability hints at a paradigm shift in interface design, where systems are not only tools but cognitive extensions that anticipate and respond to user needs.

\textbf{Establishing AI as a Co-Creative Partner in Various Domains:}
By treating AI as a partner in creative processes, this research introduces new possibilities for AI in fields like digital storytelling, content creation, and interactive media.
Future applications might expand this concept to involve AI as a creative collaborator in domains ranging from architecture and urban planning to game design and music composition.
This evolution in the AI-user relationship could redefine what it means to co-create with technology, enriching creative fields with innovative, AI-enhanced methodologies.

\textbf{Expanding the Horizons of Human-AI Collaboration in Everyday Life:}
As low-signaling, high-possibility affordances become more advanced, we may begin to see similar AI-driven AR applications embedded into everyday devices and experiences.
Imagine interfaces in smart home environments or wearable technology that blend digital information seamlessly with the physical world, allowing users to interact with AI in familiar spaces.
This vision aligns with a future where AI enhances not just specific tasks but overall daily experiences, acting as a supportive, context-aware presence in users' lives.

These implications underline the broader significance of AI-driven AR interfaces as a means to empower users, enable collaboration, and extend human cognitive capabilities.
As HCI continues to evolve, this research predicts user-centered systems that enrich both personal and professional interactions in an increasingly digital world.

\subsection{Limitations and Future Work}

While this research has demonstrated the potential of AI-driven augmented reality interfaces, several limitations were encountered that suggest areas for further exploration and refinement:

\textbf{Technical Constraints and Performance Optimization:}
Both the Totem and LLM Whiteboard platforms rely on significant computational resources, especially for real-time AI tasks like image generation and animation.
Although the use of GOSAI and optimized frameworks like ONNX helped improve performance, achieving seamless interactivity on lower-powered devices remains a challenge.
Future work could focus on refining model efficiency, possibly through further quantization techniques or the use of lightweight models tailored specifically for AR applications.

\textbf{Limited User Testing and Evaluation Scope:}
The user testing conducted for both platforms primarily involved users familiar with creative tasks or coding, potentially limiting the generalizability of the findings.
Broader testing with more diverse user groups could provide insights into how intuitive the low-signaling affordances truly are across various skill levels.
Expanding user studies to examine the impact of these interfaces on productivity, creativity, and cognitive load in different contexts would offer a more comprehensive understanding of the system’s usability.

\textbf{Narrow Focus on Specific Use Cases:}
While Totem and LLM Whiteboard represent compelling use cases for digital art and collaborative coding, they do not capture the full range of potential applications for AI-enabled AR.
Future work could explore other domains, such as medical training, education, or engineering, where real-time AI guidance in an AR environment might offer unique benefits.
Each of these fields presents unique challenges that could inform further adaptations of low-signaling, high-possibility affordances.

\textbf{Limited Exploration of Long-Term AI Adaptability:}
The current systems focus on short-term, context-aware adaptability, responding in real time to user inputs.
However, the ability of AI-driven affordances to adapt and evolve over prolonged interactions remains underexplored.
Future research could investigate ways for AI to learn from extended user interactions, developing affordances that can predict user needs and preferences over time, further reducing cognitive load and enhancing personalization.

These limitations highlight avenues for future research that could extend the findings and enhance the effectiveness of AI-driven AR interfaces across broader contexts and user groups.
Addressing these limitations would contribute to a more robust understanding of how to design adaptable, responsive interfaces that are accessible to a wide range of users.

\subsection{Final Thoughts}

% This research marks a step forward in realizing an accessible, immersive, and creative future empowered by AI-driven augmented reality within human-computer interaction.
% Through the development of the Totem and LLM Whiteboard platforms, this work illustrates the potential for AI to enhance not only creative expression but also the user experience in digital environments.
% These platforms demonstrate how AI can simplify complex tasks, provide users with intuitive, low-barrier interfaces, and invite collaborative creativity that bridges the digital and physical worlds.

% At the core of this vision is the transformative convergence of AI and HCI, which promises to reshape personal and professional landscapes alike.
% By merging advanced machine learning models with responsive, real-time AR environments, this thesis highlights how AI can go beyond functioning as a mere tool to become an active partner in creation, education, and interaction.
% The Totem and LLM Whiteboard showcase new paradigms where users are empowered to explore, collaborate, and create in ways that feel as natural as they are powerful, setting a new standard for future developments in HCI.

% Looking ahead, the implications of this research extend far beyond the applications explored here.
% As AR and AI technologies continue to advance, the concepts pioneered in this work—intuitive affordances, adaptive interfaces, and collaborative AI—hold the promise of transforming our interactions with technology, making it a seamless, supportive extension of our own creativity and cognition.
% With continued innovation, the future of AI-driven HCI is not only exciting but poised to make digital creativity more inclusive, immersive, and responsive to the needs of diverse users.

% In conclusion, this thesis lays a foundation for an AI-augmented future where technology is an enabler of human potential, enriching our experiences and expanding the horizons of what we can create.
% As AI and AR continue to evolve, the possibilities are limitless, driven by the shared goal of making our interactions with technology as empowering and expressive as possible.
% The journey toward this future is just beginning, and the work presented here offers a glimpse of what lies ahead—a world where AI and AR transform our digital experiences, making creativity accessible to all and limited only by imagination.

This research marks a significant step toward an accessible, immersive, and creatively empowering future, where AI-driven augmented reality redefines human-computer interaction.
Through the development of the Totem and LLM Whiteboard platforms, this work showcases how AI can amplify creative expression, simplify complex digital tasks, and offer low-barrier, intuitive interfaces that invite users into a collaborative dance between the digital and physical worlds.

At the core of this vision lies a convergence of AI and HCI that promises to reshape both personal and professional landscapes.
By merging advanced machine learning models with responsive, real-time AR environments, this thesis highlights how AI can transcend its role as a tool, becoming an active partner in creation, education, and interaction.
The Totem and LLM Whiteboard embody a new paradigm—one where users can explore, collaborate, and create in ways that feel natural yet profoundly powerful, setting a standard for the future of HCI.

Yet, beyond the tangible advancements, there is something more elusive and evocative at play.
In teaching machines to create, we step into an uncertain, fragile dance—a tension between control and chaos, precision and wonder.
The boundary between our inner and outer worlds begins to dissolve, inviting us into a seamless continuum of thought and expression.
In the smallest gestures—a swipe, a glance, a spoken word—we now find the power to shape entire worlds.

And with every interaction, every subtle influence the machine has on our minds, we sense a faint noise resonating in the spaces between pixels, an echo that onvites us to look deeper.
In these echoes, we wonder what secrets linger in the spaces, between transistors between bits, between atoms.
Perhaps, hidden within these silences, lies a whisper of what remains of the human condition—a reminder of the delicate balance between creator and creation, a trace of our own mysteries that linger, even as we redefine ourselves.