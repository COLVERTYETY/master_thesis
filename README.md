# Master Thesis: Expanding Interaction Boundaries: AI-Driven Augmented Reality Interfaces for Seamless Human-AI Collaboration

**Author**: Nicolas STAS  
**Date**: Not finished yet  
**Supervisors**: Clément Duhart, Marc Teyssier, Xiao Xiao 


# Introduction

## Background

In 2007, the launch of the iPhone revolutionized Human-Computer Interaction (HCI) by placing a powerful, multifunctional device directly in users' pockets, transforming everyday interactions with technology.
A cornerstone of this transformation was the iPhone's virtual keyboard, which employed predictive text algorithms to enable fast and effective typing on a small screen.
This innovation not only redefined how users interacted with mobile devices but also marked an early, impactful integration of algorithmic intelligence into consumer technology, enabling seamless usability in compact form factors.

Since then, AI has evolved significantly, driven by advancements in deep learning and the decreasing cost of computational resources.
Today, HCI has moved beyond the small screen, extending into the physical world through augmented reality (AR).
This shift from confined screens to broad, real-world interactions introduces a need to explore and define the new paradigms that AI brings to HCI.
By bridging virtual interfaces with physical spaces, modern AI-driven HCI tools like AR challenge and expand traditional interaction models, necessitating a deeper understanding of how these technologies assist users in increasingly intelligent environments.

## Research Domain
This thesis explores the affordances introduced by AI-driven augmented reality applications within Human-Computer Interaction.
The integration of AI into HCI introduces new affordances, enabling seamless, dynamic, and collaborative interactions that shift traditional paradigms.
These affordances fall within the concept of low-signaling but high-possibility interfaces, where minimal user input can yield expansive, contextually rich experiences.
This shift empowers users to accomplish more while interacting less, marking a distinct move toward efficiency and intuitiveness in digital interaction.

A key component of this research is exploring AR experiences that do not solely depend on dedicated AR hardware like headsets or advanced glasses.
Instead, we emphasize creating applications that extend beyond the screen, leveraging platforms designed to integrate with, rather than replace, the user’s physical environment.
This approach fosters inclusivity, allowing third-party participants to engage with the experience in ways that would otherwise remain invisible or inaccessible.
By tapping into these affordances, AI-enabled AR applications can facilitate shared, immersive experiences that blend seamlessly with real-world settings, offering an expanded and intuitive interaction model that aligns with the natural behavior of users and third-party participants alike.

In this way, AI-driven AR not only enhances individual interactions but also redefines the landscape of collaborative engagement, positioning technology as a flexible extension of the physical world rather than a separate or isolated entity.
This paper seeks to establish a comprehensive understanding of these affordances, their applications, and their impact on the future of HCI, highlighting the potential of AI in facilitating interactions that go beyond traditional screen-based boundaries.

## Problem Statement

Current AR interfaces in HCI lack the adaptability for seamless, collaborative interactions with AI, often requiring constrained user interaction and specialized hardware.
This thesis aims to develop dynamic AR interfaces that enable users to intuitively collaborate with AI, accomplishing complex tasks with minimal input.
% By focusing on low-signaling, high-possibility affordances, this research envisions AR as a tool for inclusive, responsive, and contextually adaptive AI-augmented environments.

## Research Questions

To deepen our understanding of AI-enabled affordances in augmented reality, this research investigates the following questions:


- What challenges are associated with designing for low-signaling, high-possibility affordances?
- How can a user collaborate with an AI system?
- How do AI-driven affordances differ from traditional affordances?


## Objectives

In response to the above questions, this research sets forth the following objectives:


- To build systems that enable users to collaborate with AI to accomplish complex creative tasks.
- To analyze how AI can foster more intuitive and expressive interactions within HCI.
- To explore real-time dynamic AI applications.


## Projects Overview and Contributions

The Totem platform and the LLM Whiteboard form the core of this research, each project explores facets of AI-enabled affordances in augmented reality.
These projects illustrate how AI and AR can combine to create dynamic, collaborative experiences that embody low-signaling, high-possibility interfaces.

### Totem Project

The Totem platform investigates the integration of AI with AR in digital art creation.
Using SDXL Turbo, a state-of-the-art diffusion model, the platform generates intricate portraits, while the First Order Motion model animates these creations, allowing users to manipulate digital art with movements in real time. 
This project embodies the thesis’s objective to foster intuitive and expressive HCI interactions by providing a highly interactive art creation experience.
The Totem enables users to explore digital art beyond the traditional screen, as their physical movements directly influence the generated images.
The result is a seamless, embodied creative process that exemplifies how AI-driven affordances enable users to accomplish more with fewer actions.

### LLM White Board Project

The LLM Whiteboard project facilitates user collaboration with a large language model in a live programming environment.
Designed to expand the understanding of physical computing concepts through AR, this project allows users to interact with a spatially aware LLM.
Using camera feeds to capture the physical environment, models interpret data while the LLM generates code based on high-level user commands.
The Whiteboard environment functions either as a blank canvas or as an overlay on a live camera feed, which enables users to experiment with physical computing concepts in a virtual space. 
This project aligns with the research objective of exploring collaborative AI applications, demonstrating how AI-driven affordances can enable creative coding processes with minimal signaling and high interpretive potential.

## Significance

By blending AI with AR in the Totem platform, users gain a new level of creative agency, generating and interacting with digital art through intuitive gestures.
This interactive experience highlights how AI can redefine affordances, empowering users to accomplish complex tasks with minimal effort and establishing a pathway for applications in digital art, entertainment, and education. The insights drawn from the Totem platform reveal how AI can translate human movement into digital influence, making it a compelling case study for integrating physical interactions with real-time generative art.

Similarly, the LLM Whiteboard showcases the possibilities of collaborative coding and physical computing within an AR framework.
By leveraging AI's capacity to interpret spatial data and generate actionable code, this project highlights how users can interact with a digital environment as if it were an extension of their physical space.
The Whiteboard provides a pathway for AI to enable complex, multi-modal tasks that would otherwise require extensive training or setup, illustrating its potential in educational settings, prototyping, and digital fabrication.

Together, these projects underscore the transformative potential of AI-enabled AR in enhancing user engagement and productivity across various applications.
They suggest a future where AR platforms move beyond traditional screens, creating environments that blend seamlessly with the physical world.
As models of high-possibility, low-signaling interfaces, Totem and the LLM Whiteboard serve as starting points for broader applications that empower users to intuitively and expressively collaborate with AI systems.